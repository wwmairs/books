<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Eight GIFs</title>
    <!-- <link rel="icon" type="img/png" href="favicons/line3.png"> -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Cousine:ital,wght@0,400;0,700;1,400;1,700&display=swap" rel="stylesheet">
    <link href="style.css?v=1.0.0" rel="stylesheet"/>
    <a name="top"></a>
</head>

<body>
    <div id="blocks-wrapper">
        <div id="pink"></div>
        <div id="paper"></div>
        <div id="yellow"></div>
        <div id="title-block">
            <h1>Eight GIFs</h1>
            <h4>wwmairs</h4>
        </div>
    </div>
    <hr>

    <div class="well" id="contents">
        <h3>Contents</h3>
        <h4><a href="#eight_gifs">Eight GIFs</a></h4>
        <h4><a href="#appendix_a">Appendix A:</a> What are these?</h4>
        <h4><a href="#appendix_b">Appendix B:</a> Tell me more.</h4>
    </div>

    <div class="number">
        <a name="eight_gifs"></a>
        <h3>1</h3>
    </div>
    <div class=well>
        <div class="gif-container">
            <img src="res/lake.gif" class="gif">
        </div>
    </div>
    
    <div class="number">
        <h3>2</h3>
    </div>
    <div class="well">
        <div class="gif-container">
            <img src="res/pipes_trucks.gif" class="gif">
        </div>
    </div>

    <div class="number">
        <h3>3</h3>
    </div>
    <div class="well">
        <div class="gif-container">
            <img src="res/outhouse.gif" class="gif">
        </div>
    </div>
    
    <div class="number">
        <h3>4</h3>
    </div>
    <div class="well">
        <div class="gif-container">
            <img src="res/truck.gif" class="gif">
        </div>
    </div>

    <div class="number">
        <h3>5</h3>
    </div>
    <div class="well">
        <div class="gif-container">
            <img src="res/inside.gif" class="gif">
        </div>
    </div>
    
    <div class="number">
        <h3>6</h3>
    </div>
    <div class="well">
        <div class="gif-container">
            <img src="res/shoes_roof.gif" class="gif">
        </div>
    </div>

    <div class="number">
        <h3>7</h3>
    </div>
    <div class="well">
        <div class="gif-container">
            <img src="res/sunset.gif" class="gif">
        </div>
    </div>
    
    <div class="number">
        <h3>8</h3>
    </div>
    <div class="well">
        <div class="gif-container">
            <img src="res/pasta_salad.gif" class="gif">
        </div>
    </div>
    <hr>
    <div class="well">
        <a name="appendix_a"></a>
        <h3>Appendix A:</h3>
        <h4>what are these?</h4>
        <p>This is a series of eight GIFs made from TIFFs made from scans of Kodak Portra 400 color negative film. The GIFs contain 16 colors: four layers of primary colors, with all possible two- and three-color combinations. I smooshed the TIFFs into GIFs with a colorspace transformation, from RGB to CMYK, and then by dithering these gradient channels into bitmaps.</p>
        <p>If you're coming here from the print edition, well, things look different here, cause this space affords different things than print. The GIFs are shown here 1 to 1, by which I mean each pixel in the image is being displayed by one pixel on your phone's display, and this is a neat thing to be able to do. But it also means that the lossy work of cropping is yours now. I performed my loss in print.</p>
        <p>This site is a single page, represented by a folder containing: a single html file, a stylesheet, and eight GIFs. It is in no way a dynamic website; every mark was put here manually by me. This is slower than pumping a word file and a zip of some images through SquareSpace or something, but it means that it's incredibly simple and requires very little to be accessed. This folder is being hosted by GitHub, which is now owned by Microsoft, and for now it costs me nothing to host. The font is provided by Google Fonts and also costs nothing. It is fetched from them every single time the page loads. If you'd like, you can look at the code <a href="https://github.com/wwmairs/books/tree/master/eight_gifs">here</a>.</p>

    </div>
    <div class="well">
        <a name="appendix_b"></a>
        <h3>Appendix B:</h3>
        <h4>tell me more.</h4>
        <p>This is a book about GIFs.</p>
        <p>Briefly, some history: the Graphics Interchange Format is an image file type, which is to say that it is a way of storing data on a computer in order to represent an image. It was developed in the mid 80s by an internet company named CompuServe, which used to be fairly important and is now just the butt of jokes and short memory in much the same way as RadioShack. Some people pronounce GIF like the peanut butter, and some people pronounce it a different way. Either way is fine, but we don’t seem to like answers like that.</p>
        <p>Most of us, I am assuming, already know what GIFs are, although we may not all know that they are called this. They are images (and yes, sometimes also short animations) on the internet. Our understanding is not some technical fact-sheet sort of knowledge, but a practiced, experiential understanding. We encounter GIFs frequently and have come to know, at least intuitively, how to interact with them, what it is that they do, what it is that we do with them. We know about GIFs in the same sort of way that we know about Hulu, or, say, chairs.</p>
        <p>But, as always, the interesting questions: what exactly are these things that we’ve learned? How do these things, and the ways in which we have come to know them, shape our worlds? My snarky but sincere answer is that these things shape our worlds importantly.</p>
        <p class="section-break">***</p>
        <p>So anyhow, what is it that GIFs do? First we need to talk, at least very briefly, about images in general, then photographic images more particularly, and, finally and most particularly, the structure of the files that hold photographic images digitally.</p>
        <p>Let’s make a distinction here between an image and the way that we represent an image through a physical medium, between a depiction of something and the material substrate of that depiction. Substrate is a sort of fussy word, but I mean to call our attention to the physical media presented to the viewer, which is something different than the image depicted, but which is the means through which we are able to see that image. The painter depicts a human face but the face that we see is not materially there on the canvas in front of us. Physically, it’s a whole mess of lines and dots and funny-shaped splotches of pigment or ink or whatever. But we don’t see this mess of lines as a mess of lines. Instead we just see a face.</p>
        <p>Computer science talks a lot about this distinction, and I was taught to frame the conversation in terms of the world of ideas and the world of things.</p>
        <p>In the world of ideas we have the images that our brains piece together for us. I look up and see the twitch of the cat’s ear casting delicate shadows on his fur as he watches the crows and squirrels across the street, dreaming sweetly of murder. We understand these things as images through an endless and endlessly broad stream of perceptions, through indeterminate fields of light, of color and intensity infinitely fine in their gradation. This is a very short and certainly insufficient description of something terribly complicated, but I think it’s good enough for right now.</p>
        <p>The world of things feels messier. We don’t have images, we have pencils. How do we communicate our ideas and images, the things we see, the things we want to be seen? We have paper and pigment, or we have acetate and tiny crumbs of silver halide crystals, or we have screens of light and tiny rectangles of additive colors.</p>
        <p>The illustrator, through some process of dark sorcery I’ll never understand, uses lines and blotchy shapes of pigment on paper to create something that we see as an image. Honestly, I don’t know how they do this, how they have come to know how to do this, this breaking down of the images we see into components, deconstructing faces into slivers and blobs of color to be reconstructed by the viewer’s sight later as the shadow of a nose or a fold of curtain hanging in the background.</p>
        <p>Some folks seem to know how to do this intuitively and wordlessly, and it seems like one of those things that the body and the subconscious do together in that silent and funny little dance of theirs. Perhaps others have both this intuitive knowledge and also the words to describe what they’re doing, and hopefully those folks are also educators who can show the rest of us schlubs what exactly is going on there. Some of you reading this can probably draw, and so I’ll ask you the question directly: how is it that you turn a pile of marks on a page into an image?</p>
        <p class="section-break">***</p>
        <p>How do we turn marks into an image? How do we depict something?</p>
        <p>Photography answers these questions for us. Or rather, the process of photography has already been designed to have sorted out this problem for us. The fussy bits have already been figured out and are abstracted away from what the artist must deal with when producing an image. Maybe this is part of what has always drawn me to photography: it gives me a tool to do something that I can’t do on my own.</p>
        <p>How do photographers depict images? Let’s separate this question into two parts, recording an image and reproducing an image. Cameras, digital or film, help us deal with the first part of the problem by recording gradients of intensity of light through a lens. They can record the absolute intensity, which makes black and white images, or they can use a fancy system of filters and color theory to record the intensities of composite colors, for example, cyan, magenta and yellow.</p>
        <p>In either case, tiny little bits of silver halide spread very thin across a piece of clear acetate film are the things doing the recording. When the film is exposed to light, these little bits either receive enough light to activate and get fixed permanently to the film, making the film opaque in that spot, or they don’t receive enough light and will be washed off when the film is processed, in which case that point on the film stays transparent.</p>
        <p>These little bits of silver halide are not all uniform in size and shape, and so their thresholds for activation are different too. Since some require a lot of light to get fixed to the film and some require only a little, the gradient intensity of light hitting the film is encoded in how many and which of these differently-sized bits harden and become opaque.</p>
        <p>These grains of opaque film are too small to see individually and we see them instead as an averaged density, a greyscale. This gradient is not infinitely fine, but it’s fine enough that we see it as continuous gradation. And when these fields of gradation are close enough to the way that we are used to seeing non-photographically, rather than just as abstracted and indiscernible washes of greys, we read them instantly and all at once as images.</p>
        <p>Now that we have our processed film, which is a reusable record of a close-enough approximation of the image as the artist shaped it, the second part of our question, how to reproduce an image, is quite simple. We can just shine light back through the film and reveal the information encoded within it.  We can do this onto photo-sensitive paper to make a print, or we can do this onto a scanner bed to make a digital file.</p>
        <p>So we can see that photographic image reproduction rests on this magic that takes place within the film. Making something that we see as an image, as a depiction of something, is dependent not only on how and how well the artist tunes their camera’s settings to shape and record light, but fundamentally on the precise way in which we take continuous information, the infinitely fine gradients of light, and record it with finite materials, a frame of film 35mm wide. We are so adept at perceiving and making sense of what we perceive that we don’t need all of this infinitely fine gradation, and we can safely discard it without affecting what the photo depicts. We don’t need to reproduce an exact copy of the light we saw, just a version that’s close enough. The magic behind the magic here is in defining what counts as close enough.</p>
        <p>In digital media, file types stand at this meeting point of recording and reproducing. They take up the task of defining how ideas and images get represented, defining what counts as close enough. Different people call this act different things. Data-science type people might call it quantization, the act of representing continuous values with discrete ones. Artists might call it abstraction. Computer scientists would call it abstraction too, but they might also refer to it as loss, particularly when speaking about image file types, describing the comparative lossiness of, for example, JPEGs and TIFFs. I think this is what a poet would call it too, loss.</p>
        <p>The truth is that these descriptions overlap and none of them alone is sufficient to describe all of what’s going on here. But I mean to call particular attention to loss, to this kind of loss, and to how this loss, which is everywhere and imperceptible by its own design, is the very mechanism of our perception. It is loss that allows us to construct meaning.</p>
        <p class="section-break">***</p>
        <p>The GIF resolves the problem of recording and reproducing images in an internet space by defining very specifically one way that a computer can represent an image. Somewhat analogously to film, GIFs record a field of values that represent light. But whereas the metallic crystals on the surface of film have varying sizes, shapes, and spacing, GIFs use a uniform grid of squares, a field of pixels, a bitmap.</p>
        <p>Other image file types take a similar approach, using a grid of values to represent a 2D pictorial space, but GIFs differ in what those values record. TIFFs, for example, use their pixels to record three intensities of light, red, green, and blue. Each channel has eight tiny bits to store this value in, which is enough for each pixel to represent any of the 16 million colors that this color model can produce (which we could call, rather formally, the gamut of the 24 bit RGB model) and this is a minor miracle worthy of its own attention.</p>
        <p>But GIFs allow only a small set of colors to be used in each image, at most 256, which is a good deal smaller than 16 million, and smaller still than infinity. Once this table of colors is defined, each pixel just needs to say which one of those colors it is.</p>
        <p>This was a computer systems engineering design choice. From what I hear, in 1987 the internet was still pretty shit. Things were, for the most part, slow and small and expensive. Computers had strange and inconsistent browsers that were really quite awful at displaying deep color gamuts, networks had terrible bandwidth, internet service providers were predatory and slow, and all these things are still pretty much true.</p>
        <p>But even in 1987 people still really wanted to send each other goofy photos and short animations. In this context something like TIFFs, though they store a much finer gradation of color and intensity of light, are really just not a good fit at all. They’ll take too long to send, they’ll take too much space to store, and, most important for viewing images through 1980s era personal computing, we can’t even guarantee that the viewer’s monitor will be able to display the colors contained in the image.</p>
        <p>We needed a file type that was small, uncomplicated, and that could easily be restricted to use only the small range of colors that monitors and browsers could be relied on to display. And so a whole bunch of designers worked very hard to come up with a file type that would make it easy to post good enough images quickly enough and accessibly enough for them to be seen and shared. They named it GIF and pronounced it like the peanut butter, and it does all of the things it was designed to do so well that it’s still how we send each other goofy photos and short animations.</p>
        <p class="section-break">***</p>
        <p>GIFs are designed such that the images they depict are guaranteed to be depictable on the screens that will display them. This is really quite clever and worth stopping to appreciate, but we won’t because we need to talk more about how exactly they do this. GIFs manage to pull off this act by limiting the number of colors that they can record. But wait, let’s quickly return to our distinction between a depiction of something and the thing that does the depicting. By restricting the number of colors that we can record, have we also restricted the number of colors that we can depict?</p>
        <p>Luckily, the answer is no, but it is a complicated no. In much the same way that the process of black and white film photography provides the artist with an already-designed way to represent continuous gradations of intensity of light using a finite representation, the process of making a GIF provides us with a way to represent continuous gradations of color using a finite number of colors.</p>
        <p>Here is where printmakers and people with pointy vision everywhere will roll their eyes and say “yes, yes, we already know about halftones, we can use very small dots of only cyan, magenta, yellow, and black ink to represent many other colors without needing to have a unique pigment for each color.” And they are right, this is how we represent colors with many printing processes. We use a very careful mess of very small dots of component colors that we see as a one solid color, and when we encounter lots of different colors in print most often they are halftones, not unique pigments.</p>
        <p>This is called the CMYK color model (the K stands for ‘Key’), and it does a very good job of representing lots and lots of colors, though not quite as many as the 24 bit RGB model. And we have all gotten quite used to seeing this kind of representation of color in print.</p>
        <p>I suspect that this is why printed things that use pure pigments to depict colors, rather than halftones, feel so different to look at; they depict things in ways we do not usually see in print, and this is part of what makes them special. If you’re not familiar with what I’m talking about here, halftones and such, try looking very closely at some printed images. I recommend a newspaper or a cereal box. Once we know that the tiny dots are there they are much easier to see, but a magnifying glass helps too.</p>
        <p>But so returning to the GIF; great, so could we use this CMYK model of color representation that works so well in print to display our web graphics in 1987? Well, no, not quite, for various reasons, but we can take a similar approach, using small bits of component colors which will, more or less, average out to the color that we want to represent. But how exactly do we decide which bits of which colors to put where?</p>
        <p>A very straightforward approach to quantization here, the abstraction of color that we must perform, would be to define the GIF’s table of 256 colors such that it has the broadest and most even range of colors possible. Then we could just go pixel by pixel and say “which of these 256 colors are you closest to? You’ll be that one now.”</p>
        <p>This doesn’t work as well as it seems like it should. GIFs made in this way have large chunks of solid colors with hard and ragged edges between them, which is not the way that we’re used to seeing light. And even more importantly, we haven’t managed to depict more colors than our medium can use for depicting, which was our goal. In fact, we have done the opposite. Our medium and choice of abstraction has forced us to remove colors from our image. We’ve chosen to perform a kind of loss that restricts what can be represented, while gaining nothing. There are mathematical ways to describe precisely how this kind of abstraction here is insufficient, but we can also just say that the images look weird and bad.</p>
        <p>Once again we are at the moment of magic, deciding how to squeeze continuous things into discrete things, the crucial and poetic moment of abstraction and quantization and averaging that I claim we must also call loss. We have arrived at the subliminal space of dithering.</p>
        <p class="section-break">***</p>
        <p>To represent a photographic image with a GIF we must lose information. If we try to avoid performing this loss, we end up restricting what is depictable. A better way to go about accepting this loss, which, it seems, we are ultimately forced to reckon with, might be to spread it out across the entirety of what we’re trying to represent. This is what dithering does.</p>
        <p>“What is dithering? Stop using all these annoying words.” <br> Ah, if only it were so simple.</p>
        <p>Dithering is, basically, a way of smoothing out too-sharp edges by picking everything up and shaking it a little bit. Smudging a pencil line with your thumb is a sort of analog and tactile dithering. It is a way to smooth unreadably noticeable edges by sort of spreading everything out a little.</p>
        <p>In the context of creating GIFs, dithering is done, most often, through a rather elegant algorithm named after its designers, Robert Floyd and Louis Steinberg. The Floyd-Steinberg algorithm works like this: look at a pixel and determine which of the 256 colors in the GIFs color table it is closest to. Set it to that color and then record the difference between the pixel’s original color and the one that it has just been set to. This difference, or error, which I like to think of as a point-in-time record of how bad a job this quantization process has done so far, is then spread out across the remaining neighboring pixels. The error is divided up and added to those pixels’ values so that later when those pixels are themselves being updated, determining which palette color to use will be taking into account all the loss that this process has already incurred. Self-correction isn’t quite what’s going on here, but rather a spreading out of loss, error diffusion, which is what this sort of dithering algorithm is called.</p>
        <p class="section-break">***</p>
        <p>Somewhat astonishingly, these images look good. Like, really quite good. Even greyscale images, which must shove their continuous spectrum of greys into the smallest recordable value possible, the bit, with each pixel allowed to be only either black or white, on or off, look phenomenal. Despite this tremendous act of discarding information, images with this kind of representational form are able to depict wide and deep gamuts of color without needing to store more than a small handful of different values. Again, minor miracles here.</p>
        <p>Taking an approach to abstraction that tries to minimize loss piecemeal, containing each pixel’s loss to itself, creates images that are at best weird and flat-looking and at worst unreadable, while still constraining what images can be represented. But taking a different approach, using error-diffusion dithering to spread this loss across our entire frame of perception, allows us to make images that look both good and readable while also reaching our goal of depicting more colors than the medium uses. And we achieved this by creating an even larger difference between the image being depicted and the physical medium that is doing the work of depicting that image, by insisting that <i>every single value will carry all their collective loss</i>. What exactly the fuck is going on here?</p>
        <p>My quiet claim, as we’re reaching the end of all this peculiar and circular pointing with words, is that all this works so well because GIFs ask that we read them in much the same way that we read analog photographs and non-photographic images too: all at once. When we see images we do absolutely zero active reconstructing of abstracted parts. We don’t say to ourselves “oh, that little darker looking thing in that corner is of a similar shape but different shade to another funny little blob,” and infer that they must be a nose and its shadow; we just see the nose and its shadow. Or all of the pieces are, for whatever reason, simply too incoherent to us, and in which case we aren’t able to read much of anything, like in those strange and vaguely disturbing moments when we jolt awake from some half-sleep and it is unclear where exactly we are, possibly it is unclear even that we are anywhere at all, and we can’t make sense of what it is that we’re looking at in our suddenly and apparently waking world, and then we say something mumbled and unintelligible and accidentally roll over onto the cat.</p>
        <p>If you look too closely at a GIF, you won’t see an image. But importantly when we do this kind of looking it’s not that we see nothing, or read nothing, but rather that we are being forced to confront the points of breakdown in a system of seeing. We are trying to read what we’re told is an image in the way that we’ve grown accustomed to reading images, in the way that the image was designed to be read, and it doesn’t work. We’re not seeing nothing, we’re seeing the world of things laid bare. We’re seeing abstraction; we’re seeing quantization; we’re seeing loss.</p>
        <p>And since the loss here is one of averaging and spreading and squishing, scale becomes the deciding factor in which losses are visible to us.  Step further back and all at once the image will snap into recognition, without warning and without explanation, and you will think hardly anything of how exactly this has happened.</p>
        <p class="section-break">***</p>
        <p>This scale is where GIFs are different from the other kinds of images that we have gotten used to reading. They were designed to work in an extremely specific context and at an extremely specific scale, and when we meet them on their terms they are luminous.</p>
        <p>But it is not 1987. We are asking more and bigger things of internet computing, but our accessible tools of communication in this world were designed for the past. When we read a GIF, which is so fundamentally shaped by its layers of loss and constraints, in formats that lay bare these abstractions, what is it that we are reading?</p>
        <p>Where does all this leave us, as artists and computer scientists and poets and philosophers? (And just to be clear I’m saying that we all are all of these things.) Beyond the fact that this nonsense is always going on in our lives and our work, I don’t really know. But this moment is important and it’s important because it is, in a literal sense of the word, unremarkable, or at the very least often unremarked. And it’s interesting, urgent, to attend to the unremarked, to the unremarkable.</p>
        <p>This is a book about GIFs. It is about GIFs and this moment of snapping-to, this strange and dual space of image and non-image, where we have built up these peculiar layers of cumulative loss, half accidentally and half intentionally. It is about GIFs and these moments of not-reading and how it is here, where the incoherent snaps suddenly and all at once into meaning, that our loss is working hardest.</p>
    </div>

    <div class="well" id="colophon">
        <h3>Colophon</h3>
        <p>This site was put together by wwmairs on January 15th 2022 in Portland OR. Text is set in Cousine.</p>
        <h4><a href="#top">^</a></h4>
    </div>

</body>
</html>
